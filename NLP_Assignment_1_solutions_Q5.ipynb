{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1 (40% of grade): Text classification for Fake News Detection - SOLUTION Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier, NaiveBayesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    \"\"\"Converts the multiple classes into two,\n",
    "    making it a binary distinction between fake news and real.\"\"\"\n",
    "    # Converting the multiclass labels to binary labels\n",
    "    labels_map = {\n",
    "        'true': 'REAL',\n",
    "        'mostly-true': 'REAL',\n",
    "        'half-true': 'REAL',\n",
    "        'false': 'FAKE',\n",
    "        'barely-true': 'FAKE',\n",
    "        'pants-fire': 'FAKE'\n",
    "    }\n",
    "    return labels_map[label]\n",
    "\n",
    "\n",
    "def parse_data_line(data_line):\n",
    "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
    "    #print(data_line)\n",
    "    return (convert_label(data_line[1]), data_line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now use same functions as Q1-4\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            (label, text) = parse_data_line(line)\n",
    "            raw_data.append((text, label))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
    "    for (text, label) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(text)),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Trying different combinations of different preprocessing and feature-extraction techniques and select optimal combination\n",
    "* For preprocessing:\n",
    "    * Switch different techniques on and off for pre-processing, find best combination from 2 to the N possible combinations of technique, including:\n",
    "        * separating out punctuation\n",
    "        * punctuation removal\n",
    "        * lowercasing\n",
    "        * stopword removal\n",
    "        * lemmatization\n",
    "        * stemming\n",
    "        * convert number words to integers or vice-versa\n",
    "        * replacing numbers with NUM\n",
    "        * replacing generic names like username handles with single token e.g. @username\n",
    "* For features:\n",
    "    * See which count/weighting for the tokens works best, including binary and BoW already tried in Q2 to weighted by sentence length, possibly using PPMI too.\n",
    "    * Try different values of N for n-gram, starting with 1, then adding in 2 etc. incrementally (keep the lower orders)\n",
    "    * Try different vocab sizes using min-df and max-df (swap out-of-vocab items with UNK token to preserve order/syntactic information?)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful libraries\n",
    "from nltk.stem import WordNetLemmatizer  # lemmatization\n",
    "import nltk # for accessing the stopwords etc.\n",
    "import re # regex\n",
    "import string # other string operations\n",
    "from textblob import TextBlob # for spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing techniques which can be turned off and on:\n",
    "preprocessing_switches = {\n",
    "        \"convert_usernames\" : False,\n",
    "        \"separate_out_punctuation\" : False,\n",
    "        \"convert_number_words_to_digits\": False,\n",
    "        \"convert_numbers\" : False,\n",
    "        \"remove_punctuation\" : False,\n",
    "        \"convert_to_lowercase\" : False,\n",
    "        \"remove_stopwords\" : False,\n",
    "        \"apply_lemmatization\" : False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different pre-processing techniques which get called altogether by pre_process\n",
    "\n",
    "# method to deal with number words being normalized to digits \n",
    "# taken from https://github.com/ShailChoksi/text2digits\n",
    "def text2int(textnum, numwords={}):\n",
    "    if not numwords:\n",
    "        units = [\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "        ]\n",
    "\n",
    "        tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "\n",
    "        scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "        numwords[\"and\"] = (1, 0)\n",
    "        for idx, word in enumerate(units):  numwords[word] = (1, idx)\n",
    "        for idx, word in enumerate(tens):       numwords[word] = (1, idx * 10)\n",
    "        for idx, word in enumerate(scales): numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
    "\n",
    "    ordinal_words = {'first':1, 'second':2, 'third':3, 'fifth':5, 'eighth':8, 'ninth':9, 'twelfth':12}\n",
    "    ordinal_endings = [('ieth', 'y'), ('th', '')]\n",
    "\n",
    "    textnum = textnum.replace('-', ' ')\n",
    "\n",
    "    current = result = 0\n",
    "    curstring = \"\"\n",
    "    onnumber = False\n",
    "    for word in textnum.split():\n",
    "        if word in ordinal_words:\n",
    "            scale, increment = (1, ordinal_words[word])\n",
    "            current = current * scale + increment\n",
    "            if scale > 100:\n",
    "                result += current\n",
    "                current = 0\n",
    "            onnumber = True\n",
    "        else:\n",
    "            for ending, replacement in ordinal_endings:\n",
    "                if word.endswith(ending):\n",
    "                    word = \"%s%s\" % (word[:-len(ending)], replacement)\n",
    "\n",
    "            if word not in numwords:\n",
    "                if onnumber:\n",
    "                    curstring += repr(result + current) + \" \"\n",
    "                curstring += word + \" \"\n",
    "                result = current = 0\n",
    "                onnumber = False\n",
    "            else:\n",
    "                scale, increment = numwords[word]\n",
    "\n",
    "                current = current * scale + increment\n",
    "                if scale > 100:\n",
    "                    result += current\n",
    "                    current = 0\n",
    "                onnumber = True\n",
    "\n",
    "    if onnumber:\n",
    "        curstring += repr(result + current)\n",
    "\n",
    "    return curstring\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if preprocessing_switches[\"separate_out_punctuation\"]:\n",
    "        text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text) # separates punctuation at ends of strings\n",
    "        text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text) # separates punctuation at beginning of strings\n",
    "    if preprocessing_switches[\"convert_numbers\"]:\n",
    "        text = re.sub('\\d+', 'NUMBER',text)\n",
    "    # print(\"tokenising:\", text) # uncomment for debugging\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def remove_characters_after_tokenization(tokens):\n",
    "    # note preserving critical social media/twitter characters @ and #\n",
    "    p = '[{}]'.format(re.escape(string.punctuation)+'\\…').replace(\"@\", \"\").replace(\"\\#\", \"\")\n",
    "    #print(p)\n",
    "    pattern = re.compile(p)\n",
    "    filtered_tokens = [f for f in filter(None, [pattern.sub('', token) for token in tokens])]\n",
    "    return filtered_tokens\n",
    "\n",
    "def convert_to_lowercase(tokens):\n",
    "    return [token.lower() for token in tokens if token.isalpha()]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens\n",
    "\n",
    "def apply_lemmatization(tokens, wnl=WordNetLemmatizer()):   \n",
    "    return [wnl.lemmatize(token) for token in tokens]\n",
    "\n",
    "def pre_process(text):\n",
    "    \"\"\" Technique which will apply the techniques if they are set to \n",
    "    True in the global dict ::preprocessing_switches::\n",
    "    \"\"\"\n",
    "    if preprocessing_switches[\"convert_usernames\"]:\n",
    "        text = re.sub(\"@[a-zA-Z0-9:.]+\", \"@username\", text)\n",
    "    if preprocessing_switches[\"convert_number_words_to_digits\"]:\n",
    "        text = text2int(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    if preprocessing_switches[\"remove_punctuation\"]:\n",
    "        tokens = remove_characters_after_tokenization(tokens)\n",
    "    if preprocessing_switches[\"convert_to_lowercase\"]:\n",
    "        tokens = convert_to_lowercase(tokens)\n",
    "    if preprocessing_switches[\"remove_stopwords\"]:\n",
    "        tokens = remove_stopwords(tokens)\n",
    "    if preprocessing_switches[\"apply_lemmatization\"]:\n",
    "        tokens = apply_lemmatization(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@colonelkickhead:', 'Another', 'bloody', 'instant', 'restaurant', 'week?!?!', 'Seriously!', 'They', 'just', 'jumped', 'the', 'shark', 'riding', 'two', 'other', 'sharks', 'powered', 'by', 'sh…']\n",
      "['RT', '@username', 'Another', 'bloody', 'instant', 'restaurant', 'week?!?!', 'Seriously!', 'They', 'just', 'jumped', 'the', 'shark', 'riding', 'two', 'other', 'sharks', 'powered', 'by', 'sh…']\n",
      "['RT', '@username', 'Another', 'bloody', 'instant', 'restaurant', 'week?!?!', 'Seriously!', 'They', 'just', 'jumped', 'the', 'shark', 'riding', '2', 'other', 'sharks', 'powered', 'by', 'sh…']\n",
      "['RT', '@username', 'Another', 'bloody', 'instant', 'restaurant', 'week', '?!?!', 'Seriously', '!', 'They', 'just', 'jumped', 'the', 'shark', 'riding', '2', 'other', 'sharks', 'powered', 'by', 'sh…']\n",
      "['RT', '@username', 'Another', 'bloody', 'instant', 'restaurant', 'week', '?!?!', 'Seriously', '!', 'They', 'just', 'jumped', 'the', 'shark', 'riding', 'NUMBER', 'other', 'sharks', 'powered', 'by', 'sh…']\n",
      "['RT', '@username', 'Another', 'bloody', 'instant', 'restaurant', 'week', 'Seriously', 'They', 'just', 'jumped', 'the', 'shark', 'riding', 'NUMBER', 'other', 'sharks', 'powered', 'by', 'sh']\n",
      "['rt', 'another', 'bloody', 'instant', 'restaurant', 'week', 'seriously', 'they', 'just', 'jumped', 'the', 'shark', 'riding', 'number', 'other', 'sharks', 'powered', 'by', 'sh']\n",
      "['rt', 'another', 'bloody', 'instant', 'restaurant', 'week', 'seriously', 'jumped', 'shark', 'riding', 'number', 'sharks', 'powered', 'sh']\n",
      "['rt', 'another', 'bloody', 'instant', 'restaurant', 'week', 'seriously', 'jumped', 'shark', 'riding', 'number', 'shark', 'powered', 'sh']\n"
     ]
    }
   ],
   "source": [
    "# try some of these combos\n",
    "text = \"RT @colonelkickhead: Another bloody instant restaurant week?!?! Seriously! They just jumped the shark riding two other sharks powered by sh…\"\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"convert_usernames\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"convert_number_words_to_digits\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"separate_out_punctuation\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"convert_numbers\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"remove_punctuation\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"convert_to_lowercase\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"remove_stopwords\"] = True\n",
    "print(pre_process(text))\n",
    "preprocessing_switches[\"apply_lemmatization\"] = True\n",
    "print(pre_process(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset all to false to search for finding best combination\n",
    "preprocessing_switches = {k: False for k in preprocessing_switches.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change cross-val function to allow first fold only option\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cross_validate(dataset, folds, first_fold_only=False):\n",
    "    results = []\n",
    "    fold_size = int(len(dataset)/folds) + 1\n",
    "    \n",
    "    for i in range(0,len(dataset),int(fold_size)):\n",
    "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
    "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
    "        \n",
    "        fold_test_data = dataset[i:i+fold_size]   # get test split on this fold\n",
    "        fold_train_data = dataset[:i] + dataset[i+fold_size:] # get train split on this fold\n",
    "        classifier = train_classifier(fold_train_data) # train classifier on the training data\n",
    "        y_true = [x[1] for x in fold_test_data] # get ground-truth labels\n",
    "        y_pred = predict_labels([x[0] for x in fold_test_data], classifier) # use classifier to predict\n",
    "        results.append(precision_recall_fscore_support(y_true, y_pred, average='weighted')) # get results\n",
    "        # print(classification_report(y_true,y_pred))  # see classification report for fold\n",
    "        \n",
    "        #alternative: focus on the FAKE label accuracy only\n",
    "        #report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        #results.append([report[\"FAKE\"]['precision'], report[\"FAKE\"]['recall'], report[\"FAKE\"]['f1-score']]) # focus on FAKE\n",
    "        if first_fold_only:\n",
    "            break # quicker version only using one fold\n",
    "        \n",
    "    avg_results = [np.mean([x[0] for x in results]),\n",
    "                   np.mean([x[1] for x in results]),\n",
    "                   np.mean([x[2] for x in results])\n",
    "                ]\n",
    "    return avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now just use the answer to Q2 for feature extraction (unigram bow binary)\n",
    "global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "# Solution\n",
    "from collections import Counter\n",
    "\n",
    "def to_feature_vector(tokens):\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "    # Just returning all words in the \n",
    "    #feature_vector = Counter(tokens) # Bag-of-Words counts\n",
    "    feature_vector = {x:1 for x in Counter(tokens).keys()}  # binary Set-of-Words\n",
    "    global_feature_dict.update(feature_vector) # just add all counts\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(data)\n",
    "\n",
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all combinations of pre-processing technique\n",
    "from itertools import chain, combinations  # for powerset, to get all combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "combos = [list(p) for p in powerset(preprocessing_switches.keys())]\n",
    "best_f_score = 0  # initial best mean accuracy to beat\n",
    "best_switches = []\n",
    "results = []\n",
    "\n",
    "if False:  # Takes some time to run- set to True to reproduce fully\n",
    "    for switches in combos:\n",
    "        preprocessing_switches = {k : False for k in preprocessing_switches.keys()}\n",
    "        for switch in switches:\n",
    "            preprocessing_switches[switch] = True\n",
    "        print(\"*\" * 30)\n",
    "        print(preprocessing_switches)\n",
    "        # loading reviews\n",
    "        # initialize global lists that will be appended to by the methods below\n",
    "        raw_data = []          # the filtered data from the dataset file\n",
    "        train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "        test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "        # references to the data files\n",
    "        data_file_path = 'fake_news.tsv'\n",
    "\n",
    "        # Do the actual stuff (i.e. call the functions we've made)\n",
    "        # We parse the dataset and put it in a raw data list\n",
    "        print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "              \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "        load_data(data_file_path) \n",
    "\n",
    "        # We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "        # You do the cross validation on the 80% (training data)\n",
    "        # We print the number of training samples and the number of features before the split\n",
    "        print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "              \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "        global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "        split_and_preprocess_data(0.8)\n",
    "\n",
    "        # let's look at the representation of the first instance of training:\n",
    "        print(train_data[0])\n",
    "\n",
    "        # We print the number of training samples and the number of features after the split\n",
    "        print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "              \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "\n",
    "        all_scores = cross_validate(train_data, 10, first_fold_only=False)\n",
    "        f_score = all_scores[2]\n",
    "        print(f_score)\n",
    "        results.append([(k,v) for k,v in preprocessing_switches.items()] + all_scores)\n",
    "        print(\"*\" * 40)\n",
    "        #plot_heat_map_similarity(df)\n",
    "        if f_score >= best_f_score:\n",
    "            best_f_score = f_score\n",
    "            best_switches = switches\n",
    "\n",
    "    # make the preprocessing switches the best one:\n",
    "    best_preprocessing_switches = {k : False for k in preprocessing_switches.keys()}\n",
    "    for switch in best_switches:\n",
    "        best_preprocessing_switches[switch] = True\n",
    "    print(\"*\" * 50)\n",
    "    print(\"best f-score\", best_f_score)\n",
    "    print(\"best combo\", best_preprocessing_switches) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>convert_usernames</th>\n",
       "      <th>separate_out_punctuation</th>\n",
       "      <th>convert_number_words_to_digits</th>\n",
       "      <th>convert_numbers</th>\n",
       "      <th>remove_punctuation</th>\n",
       "      <th>convert_to_lowercase</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>apply_lemmatization</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.574330</td>\n",
       "      <td>0.574486</td>\n",
       "      <td>0.574071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.574330</td>\n",
       "      <td>0.574486</td>\n",
       "      <td>0.574071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.571949</td>\n",
       "      <td>0.573245</td>\n",
       "      <td>0.572172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.571950</td>\n",
       "      <td>0.573245</td>\n",
       "      <td>0.572170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571698</td>\n",
       "      <td>0.572633</td>\n",
       "      <td>0.571775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571309</td>\n",
       "      <td>0.572267</td>\n",
       "      <td>0.571402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571051</td>\n",
       "      <td>0.571802</td>\n",
       "      <td>0.571096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571040</td>\n",
       "      <td>0.571802</td>\n",
       "      <td>0.571081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.570599</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.570781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.569952</td>\n",
       "      <td>0.571190</td>\n",
       "      <td>0.570137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569762</td>\n",
       "      <td>0.569721</td>\n",
       "      <td>0.569377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569623</td>\n",
       "      <td>0.569599</td>\n",
       "      <td>0.569257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.568532</td>\n",
       "      <td>0.568504</td>\n",
       "      <td>0.568029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.568532</td>\n",
       "      <td>0.568504</td>\n",
       "      <td>0.568029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568156</td>\n",
       "      <td>0.568384</td>\n",
       "      <td>0.568008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568078</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.567912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568625</td>\n",
       "      <td>0.568267</td>\n",
       "      <td>0.567874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568625</td>\n",
       "      <td>0.568267</td>\n",
       "      <td>0.567874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567813</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.567653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567816</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.567637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567603</td>\n",
       "      <td>0.567768</td>\n",
       "      <td>0.567333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567462</td>\n",
       "      <td>0.567646</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.567177</td>\n",
       "      <td>0.567882</td>\n",
       "      <td>0.567165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.567267</td>\n",
       "      <td>0.567284</td>\n",
       "      <td>0.567001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.566950</td>\n",
       "      <td>0.567637</td>\n",
       "      <td>0.566930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.567174</td>\n",
       "      <td>0.567161</td>\n",
       "      <td>0.566888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567300</td>\n",
       "      <td>0.567176</td>\n",
       "      <td>0.566782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567300</td>\n",
       "      <td>0.567176</td>\n",
       "      <td>0.566782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.566192</td>\n",
       "      <td>0.567158</td>\n",
       "      <td>0.566272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.566047</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.566193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555837</td>\n",
       "      <td>0.556063</td>\n",
       "      <td>0.555288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555842</td>\n",
       "      <td>0.556056</td>\n",
       "      <td>0.555278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555842</td>\n",
       "      <td>0.556056</td>\n",
       "      <td>0.555278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555531</td>\n",
       "      <td>0.555678</td>\n",
       "      <td>0.555257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555372</td>\n",
       "      <td>0.556568</td>\n",
       "      <td>0.555129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555372</td>\n",
       "      <td>0.556568</td>\n",
       "      <td>0.555129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.554711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.554711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.554361</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.554151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.554361</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.554151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.554043</td>\n",
       "      <td>0.555446</td>\n",
       "      <td>0.553965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.554043</td>\n",
       "      <td>0.555446</td>\n",
       "      <td>0.553965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553584</td>\n",
       "      <td>0.554257</td>\n",
       "      <td>0.553164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553584</td>\n",
       "      <td>0.554257</td>\n",
       "      <td>0.553164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552930</td>\n",
       "      <td>0.554480</td>\n",
       "      <td>0.552843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552930</td>\n",
       "      <td>0.554480</td>\n",
       "      <td>0.552843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553119</td>\n",
       "      <td>0.553872</td>\n",
       "      <td>0.552822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553119</td>\n",
       "      <td>0.553872</td>\n",
       "      <td>0.552822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553222</td>\n",
       "      <td>0.553883</td>\n",
       "      <td>0.552802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553222</td>\n",
       "      <td>0.553883</td>\n",
       "      <td>0.552802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552283</td>\n",
       "      <td>0.553256</td>\n",
       "      <td>0.552169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552283</td>\n",
       "      <td>0.553256</td>\n",
       "      <td>0.552169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552620</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.552108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552202</td>\n",
       "      <td>0.552900</td>\n",
       "      <td>0.551859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552202</td>\n",
       "      <td>0.552900</td>\n",
       "      <td>0.551859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552178</td>\n",
       "      <td>0.552143</td>\n",
       "      <td>0.551637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.551557</td>\n",
       "      <td>0.552906</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.551557</td>\n",
       "      <td>0.552906</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.549925</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.549901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.549925</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.549901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     convert_usernames  separate_out_punctuation  \\\n",
       "0                False                     False   \n",
       "1                 True                     False   \n",
       "2                 True                     False   \n",
       "3                False                     False   \n",
       "4                 True                     False   \n",
       "5                False                     False   \n",
       "6                False                     False   \n",
       "7                 True                     False   \n",
       "8                 True                     False   \n",
       "9                False                     False   \n",
       "10                True                     False   \n",
       "11               False                     False   \n",
       "12               False                      True   \n",
       "13                True                      True   \n",
       "14                True                     False   \n",
       "15               False                     False   \n",
       "16               False                      True   \n",
       "17                True                      True   \n",
       "18                True                     False   \n",
       "19               False                     False   \n",
       "20               False                      True   \n",
       "21                True                      True   \n",
       "22                True                      True   \n",
       "23                True                      True   \n",
       "24               False                      True   \n",
       "25               False                      True   \n",
       "26               False                      True   \n",
       "27                True                      True   \n",
       "28                True                     False   \n",
       "29                True                     False   \n",
       "..                 ...                       ...   \n",
       "226               True                      True   \n",
       "227              False                     False   \n",
       "228               True                     False   \n",
       "229              False                      True   \n",
       "230              False                     False   \n",
       "231               True                     False   \n",
       "232              False                     False   \n",
       "233               True                     False   \n",
       "234              False                     False   \n",
       "235               True                     False   \n",
       "236              False                     False   \n",
       "237               True                     False   \n",
       "238              False                     False   \n",
       "239               True                     False   \n",
       "240              False                     False   \n",
       "241               True                     False   \n",
       "242              False                     False   \n",
       "243               True                     False   \n",
       "244              False                     False   \n",
       "245               True                     False   \n",
       "246              False                      True   \n",
       "247               True                      True   \n",
       "248               True                      True   \n",
       "249              False                     False   \n",
       "250               True                     False   \n",
       "251              False                      True   \n",
       "252              False                     False   \n",
       "253               True                     False   \n",
       "254              False                     False   \n",
       "255               True                     False   \n",
       "\n",
       "     convert_number_words_to_digits  convert_numbers  remove_punctuation  \\\n",
       "0                             False            False               False   \n",
       "1                             False            False               False   \n",
       "2                              True             True               False   \n",
       "3                              True             True               False   \n",
       "4                              True             True               False   \n",
       "5                              True             True               False   \n",
       "6                             False             True               False   \n",
       "7                             False             True               False   \n",
       "8                             False             True               False   \n",
       "9                             False             True               False   \n",
       "10                             True            False               False   \n",
       "11                             True            False               False   \n",
       "12                             True             True                True   \n",
       "13                             True             True                True   \n",
       "14                            False            False               False   \n",
       "15                            False            False               False   \n",
       "16                            False             True               False   \n",
       "17                            False             True               False   \n",
       "18                             True            False               False   \n",
       "19                             True            False               False   \n",
       "20                             True             True               False   \n",
       "21                             True             True               False   \n",
       "22                             True             True               False   \n",
       "23                            False             True               False   \n",
       "24                             True             True               False   \n",
       "25                            False             True               False   \n",
       "26                            False            False               False   \n",
       "27                            False            False               False   \n",
       "28                             True             True               False   \n",
       "29                            False             True               False   \n",
       "..                              ...              ...                 ...   \n",
       "226                           False            False                True   \n",
       "227                           False            False                True   \n",
       "228                           False            False                True   \n",
       "229                            True            False                True   \n",
       "230                           False             True               False   \n",
       "231                           False             True               False   \n",
       "232                            True            False               False   \n",
       "233                            True            False               False   \n",
       "234                            True            False                True   \n",
       "235                            True            False                True   \n",
       "236                            True             True               False   \n",
       "237                            True             True               False   \n",
       "238                           False            False               False   \n",
       "239                           False            False               False   \n",
       "240                            True            False               False   \n",
       "241                            True            False               False   \n",
       "242                            True             True               False   \n",
       "243                            True             True               False   \n",
       "244                           False             True               False   \n",
       "245                           False             True               False   \n",
       "246                            True            False                True   \n",
       "247                            True            False                True   \n",
       "248                            True            False                True   \n",
       "249                            True            False               False   \n",
       "250                            True            False               False   \n",
       "251                            True            False                True   \n",
       "252                           False            False               False   \n",
       "253                           False            False               False   \n",
       "254                            True             True               False   \n",
       "255                            True             True               False   \n",
       "\n",
       "     convert_to_lowercase  remove_stopwords  apply_lemmatization         p  \\\n",
       "0                   False             False                False  0.574330   \n",
       "1                   False             False                False  0.574330   \n",
       "2                   False             False                 True  0.571949   \n",
       "3                   False             False                 True  0.571950   \n",
       "4                   False             False                False  0.571698   \n",
       "5                   False             False                False  0.571309   \n",
       "6                   False             False                False  0.571051   \n",
       "7                   False             False                False  0.571040   \n",
       "8                   False             False                 True  0.570599   \n",
       "9                   False             False                 True  0.569952   \n",
       "10                  False             False                False  0.569762   \n",
       "11                  False             False                False  0.569623   \n",
       "12                   True              True                False  0.568532   \n",
       "13                   True              True                False  0.568532   \n",
       "14                  False             False                 True  0.568156   \n",
       "15                  False             False                 True  0.568078   \n",
       "16                   True             False                 True  0.568625   \n",
       "17                   True             False                 True  0.568625   \n",
       "18                  False             False                 True  0.567813   \n",
       "19                  False             False                 True  0.567816   \n",
       "20                  False             False                 True  0.567603   \n",
       "21                  False             False                 True  0.567462   \n",
       "22                  False             False                False  0.567177   \n",
       "23                  False             False                False  0.567267   \n",
       "24                  False             False                False  0.566950   \n",
       "25                  False             False                False  0.567174   \n",
       "26                   True             False                 True  0.567300   \n",
       "27                   True             False                 True  0.567300   \n",
       "28                  False              True                 True  0.566192   \n",
       "29                  False              True                 True  0.566047   \n",
       "..                    ...               ...                  ...       ...   \n",
       "226                  True              True                 True  0.555837   \n",
       "227                  True              True                 True  0.555842   \n",
       "228                  True              True                 True  0.555842   \n",
       "229                 False              True                False  0.555531   \n",
       "230                  True              True                 True  0.555372   \n",
       "231                  True              True                 True  0.555372   \n",
       "232                  True              True                False  0.554548   \n",
       "233                  True              True                False  0.554548   \n",
       "234                  True              True                 True  0.554361   \n",
       "235                  True              True                 True  0.554361   \n",
       "236                  True              True                False  0.554043   \n",
       "237                  True              True                False  0.554043   \n",
       "238                  True             False                 True  0.553584   \n",
       "239                  True             False                 True  0.553584   \n",
       "240                  True              True                 True  0.552930   \n",
       "241                  True              True                 True  0.552930   \n",
       "242                  True             False                 True  0.553119   \n",
       "243                  True             False                 True  0.553119   \n",
       "244                  True             False                 True  0.553222   \n",
       "245                  True             False                 True  0.553222   \n",
       "246                  True              True                 True  0.552283   \n",
       "247                  True              True                 True  0.552283   \n",
       "248                 False              True                 True  0.552620   \n",
       "249                  True             False                 True  0.552202   \n",
       "250                  True             False                 True  0.552202   \n",
       "251                 False              True                 True  0.552178   \n",
       "252                  True              True                 True  0.551557   \n",
       "253                  True              True                 True  0.551557   \n",
       "254                  True              True                 True  0.549925   \n",
       "255                  True              True                 True  0.549925   \n",
       "\n",
       "            r   f-score  \n",
       "0    0.574486  0.574071  \n",
       "1    0.574486  0.574071  \n",
       "2    0.573245  0.572172  \n",
       "3    0.573245  0.572170  \n",
       "4    0.572633  0.571775  \n",
       "5    0.572267  0.571402  \n",
       "6    0.571802  0.571096  \n",
       "7    0.571802  0.571081  \n",
       "8    0.571800  0.570781  \n",
       "9    0.571190  0.570137  \n",
       "10   0.569721  0.569377  \n",
       "11   0.569599  0.569257  \n",
       "12   0.568504  0.568029  \n",
       "13   0.568504  0.568029  \n",
       "14   0.568384  0.568008  \n",
       "15   0.568261  0.567912  \n",
       "16   0.568267  0.567874  \n",
       "17   0.568267  0.567874  \n",
       "18   0.568000  0.567653  \n",
       "19   0.568000  0.567637  \n",
       "20   0.567768  0.567333  \n",
       "21   0.567646  0.567200  \n",
       "22   0.567882  0.567165  \n",
       "23   0.567284  0.567001  \n",
       "24   0.567637  0.566930  \n",
       "25   0.567161  0.566888  \n",
       "26   0.567176  0.566782  \n",
       "27   0.567176  0.566782  \n",
       "28   0.567158  0.566272  \n",
       "29   0.567052  0.566193  \n",
       "..        ...       ...  \n",
       "226  0.556063  0.555288  \n",
       "227  0.556056  0.555278  \n",
       "228  0.556056  0.555278  \n",
       "229  0.555678  0.555257  \n",
       "230  0.556568  0.555129  \n",
       "231  0.556568  0.555129  \n",
       "232  0.556543  0.554711  \n",
       "233  0.556543  0.554711  \n",
       "234  0.555205  0.554151  \n",
       "235  0.555205  0.554151  \n",
       "236  0.555446  0.553965  \n",
       "237  0.555446  0.553965  \n",
       "238  0.554257  0.553164  \n",
       "239  0.554257  0.553164  \n",
       "240  0.554480  0.552843  \n",
       "241  0.554480  0.552843  \n",
       "242  0.553872  0.552822  \n",
       "243  0.553872  0.552822  \n",
       "244  0.553883  0.552802  \n",
       "245  0.553883  0.552802  \n",
       "246  0.553256  0.552169  \n",
       "247  0.553256  0.552169  \n",
       "248  0.552632  0.552108  \n",
       "249  0.552900  0.551859  \n",
       "250  0.552900  0.551859  \n",
       "251  0.552143  0.551637  \n",
       "252  0.552906  0.551426  \n",
       "253  0.552906  0.551426  \n",
       "254  0.551435  0.549901  \n",
       "255  0.551435  0.549901  \n",
       "\n",
       "[256 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's display all the results in a pandas dataframe\n",
    "import pandas as pd\n",
    "if False:  # set as False if above search not run\n",
    "    results = sorted(results, key=lambda x:x[-1], reverse=True) # sort results from best to worst f-score\n",
    "    df = pd.DataFrame([[x[1] for x in row[:-3]] + row[-3:] for row in results],\n",
    "                  columns=[x[0] for x in results[0][:-3]] + [\"p\", \"r\", \"f-score\"])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_usernames 0.5611854745741123\n",
      "separate_out_punctuation 0.5614473546115063\n",
      "convert_number_words_to_digits 0.5609313888789945\n",
      "convert_numbers 0.5622447694084758\n",
      "remove_punctuation 0.560395938235528\n",
      "convert_to_lowercase 0.5598332727974165\n",
      "remove_stopwords 0.5591552225659394\n",
      "apply_lemmatization 0.5602393378389651\n"
     ]
    }
   ],
   "source": [
    "# which feature being true tends to help more?\n",
    "if False:  # set as False if above search not run\n",
    "    for key in preprocessing_switches.keys():\n",
    "        print(key, sum(df[df[key]==True]['f-score']) / len(df[df[key]==True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best options found for binary bag-of-words (by running above search)\n",
    "preprocessing_switches = {'convert_usernames': True, 'separate_out_punctuation': False,\n",
    "                          'convert_number_words_to_digits': False, 'convert_numbers': False,\n",
    "                          'remove_punctuation': False, 'convert_to_lowercase': False,\n",
    "                          'remove_stopwords': False, 'apply_lemmatization': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on pre-processing (for report)\n",
    "* This cross-validation set-up for binary bag/set-of-words approach only had one setting which equalled the performance of the base line of a simple split on white space tokenization, which was using the **replacing usernames with @username** as the only preprocessing technique (with no other techniques). Given this reduces the number of features, all-else-being equal can be seen as better than no preprocessing at all despite the identical performance.\n",
    "* However, it seems the **conversion of numbers (from word numbers to integers)** is the best preprocessing technique in combination with the others, followed by the separation of punctuation, then converting the usernames, so all three of these could be useful.\n",
    "* This result may not hold when using other features/weightings and may need to be re-done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Get best feature extraction technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different settings\n",
    "count_weights = [\"binary\", \"counts\", \"weighted\"]\n",
    "ngram_feature_range = range(1,6)\n",
    "feature_set_sizes = [500,1000,100000,100000,1000000]\n",
    "\n",
    "# global variables to be used by to_feature_vector\n",
    "_WEIGHT_ = \"binary\"  # starting value/baseline\n",
    "_N_ = 1  # starting value/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature_vector(tokens):\n",
    "    # SOLUTION: a method to extract different ngram sequences from tokens\n",
    "    # and different weighting on those counts\n",
    "    \n",
    "    feature_vector_dict =  Counter()  # local feature vector for counts\n",
    "    \n",
    "    # collect the counts for all n in range (1,_N_)\n",
    "    for n in range(1,_N_+1):\n",
    "        new_tokens = [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "        for i in range(n-1, len(new_tokens)):\n",
    "            raw_ngram = \" \".join(new_tokens[i-(n-1):i+1])\n",
    "            #print(raw_ngram)\n",
    "            n_gram = \"{}@{}\".format(n, raw_ngram)\n",
    "            #print(n_gram)\n",
    "            feature_vector_dict[n_gram]+=1\n",
    "    \n",
    "    # if _WEIGHT_ is 'counts' then this has already been done\n",
    "    if _WEIGHT_ == \"binary\":\n",
    "        feature_vector_dict = {x:1 for x in feature_vector_dict.keys()}  # binary Set-of-Words\n",
    "    elif _WEIGHT_ == \"weighted\":\n",
    "        # bag-of-words counts \n",
    "        feature_vector_dict = {x:feature_vector_dict[x]/(len(tokens)+1) for x in feature_vector_dict.keys()}\n",
    "    \n",
    "    for feat,v in feature_vector_dict.items():\n",
    "        if not feat in global_feature_dict:\n",
    "            global_feature_dict[feat] = 1\n",
    "        else:\n",
    "            global_feature_dict[feat] +=1\n",
    "            \n",
    "    return feature_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_feature_extraction = []\n",
    "best_f_score = 0  # initial best mean accuracy to beat\n",
    "best_feature_extraction = {\"n\": None, \"w\": None} # best settings\n",
    "\n",
    "if False: # set to True to run. Takes a little bit of time n * w settings\n",
    "    print(preprocessing_switches)\n",
    "    for w in count_weights:\n",
    "        for n in ngram_feature_range:\n",
    "            #for k in feature_set_sizes:\n",
    "            #    print(w,n,k)\n",
    "            _N_ = n\n",
    "            _WEIGHT_ = w\n",
    "            raw_data = []          # the filtered data from the dataset file\n",
    "            train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "            test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "            # references to the data files\n",
    "            data_file_path = 'fake_news.tsv'\n",
    "\n",
    "            # Do the actual stuff (i.e. call the functions we've made)\n",
    "            # We parse the dataset and put it in a raw data list\n",
    "            print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "                  \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "            load_data(data_file_path) \n",
    "\n",
    "            # We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "            # You do the cross validation on the 80% (training data)\n",
    "            # We print the number of training samples and the number of features before the split\n",
    "            print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "                  \"Preparing training and test data...\",sep='\\n')\n",
    "            global_feature_dict = {}\n",
    "            split_and_preprocess_data(0.8)\n",
    "\n",
    "            # We print the number of training samples and the number of features after the split\n",
    "            print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "                  \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "\n",
    "            all_scores = cross_validate(train_data, 10, first_fold_only=True)\n",
    "            f_score = all_scores[2]\n",
    "            print(f_score)\n",
    "            print(w, n, all_scores)\n",
    "            results_feature_extraction.append((w, n, all_scores))\n",
    "            if f_score > best_f_score:\n",
    "                best_f_score = f_score\n",
    "                best_feature_extraction['w'] = w\n",
    "                best_feature_extraction['n'] = n\n",
    "    print(\"best f-score\", best_f_score, \"with best settings\", best_feature_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>counts</td>\n",
       "      <td>4</td>\n",
       "      <td>0.603976</td>\n",
       "      <td>0.607569</td>\n",
       "      <td>0.604007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "      <td>0.602991</td>\n",
       "      <td>0.606954</td>\n",
       "      <td>0.602984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>0.602647</td>\n",
       "      <td>0.605488</td>\n",
       "      <td>0.602902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>0.603206</td>\n",
       "      <td>0.607930</td>\n",
       "      <td>0.602482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>counts</td>\n",
       "      <td>5</td>\n",
       "      <td>0.602194</td>\n",
       "      <td>0.606475</td>\n",
       "      <td>0.601909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>counts</td>\n",
       "      <td>3</td>\n",
       "      <td>0.598229</td>\n",
       "      <td>0.600860</td>\n",
       "      <td>0.598437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590362</td>\n",
       "      <td>0.592050</td>\n",
       "      <td>0.590649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted</td>\n",
       "      <td>4</td>\n",
       "      <td>0.603066</td>\n",
       "      <td>0.608789</td>\n",
       "      <td>0.588534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588137</td>\n",
       "      <td>0.589492</td>\n",
       "      <td>0.588354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weighted</td>\n",
       "      <td>5</td>\n",
       "      <td>0.603644</td>\n",
       "      <td>0.609153</td>\n",
       "      <td>0.587914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>0.601110</td>\n",
       "      <td>0.607198</td>\n",
       "      <td>0.587511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>0.599261</td>\n",
       "      <td>0.605846</td>\n",
       "      <td>0.586832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>weighted</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597165</td>\n",
       "      <td>0.603905</td>\n",
       "      <td>0.583322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574330</td>\n",
       "      <td>0.574486</td>\n",
       "      <td>0.574071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>counts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569398</td>\n",
       "      <td>0.569357</td>\n",
       "      <td>0.569046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weight  n         p         r   f-score\n",
       "0     counts  4  0.603976  0.607569  0.604007\n",
       "1     binary  4  0.602991  0.606954  0.602984\n",
       "2     binary  3  0.602647  0.605488  0.602902\n",
       "3     binary  5  0.603206  0.607930  0.602482\n",
       "4     counts  5  0.602194  0.606475  0.601909\n",
       "5     counts  3  0.598229  0.600860  0.598437\n",
       "6     binary  2  0.590362  0.592050  0.590649\n",
       "7   weighted  4  0.603066  0.608789  0.588534\n",
       "8     counts  2  0.588137  0.589492  0.588354\n",
       "9   weighted  5  0.603644  0.609153  0.587914\n",
       "10  weighted  3  0.601110  0.607198  0.587511\n",
       "11  weighted  2  0.599261  0.605846  0.586832\n",
       "12  weighted  1  0.597165  0.603905  0.583322\n",
       "13    binary  1  0.574330  0.574486  0.574071\n",
       "14    counts  1  0.569398  0.569357  0.569046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if False:  # set to False if above search is not run\n",
    "    # sort the results by best f-score:\n",
    "    results_feature_extraction = sorted(results_feature_extraction, key=lambda x:x[-1][-1], reverse=True)\n",
    "    df = pd.DataFrame([[x for x in row[:-1]] + list(row[-1]) for row in results_feature_extraction],\n",
    "                  columns=[\"weight\", \"n\", \"p\", \"r\", \"f-score\"])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary 0.5946175136448995\n",
      "counts 0.5923506330604917\n",
      "weighted 0.5868226306604838\n"
     ]
    }
   ],
   "source": [
    "# which feature counting/weights technique is most useful (in combination with other params)?\n",
    "if False:  # set to False if above search is not run\n",
    "    for w in count_weights:\n",
    "        print(w, sum(df[df[\"weight\"]==w]['f-score'])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5754796790376412\n",
      "2 0.5886115914396407\n",
      "3 0.5962832258837417\n",
      "4 0.5985085325336533\n",
      "5 0.5974349333817814\n"
     ]
    }
   ],
   "source": [
    "# which ngram n value is most useful (in combination with other params)?\n",
    "if False:  # set to False if above search is not run\n",
    "    for n in range(1,6):\n",
    "        print(n, sum(df[df[\"n\"]==n]['f-score'])/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on feature extraction (for report)\n",
    "*  Using the best preprocessing technique found in the baseline unigram binary set-of-words setting, the best feature extraction techqniues were using an **n-gram range of (1,4)** and using **bag-of-words counts**. The f-score in cross-val has improved from the baseline 0.574 (unigram binary set-of-words) to **0.604**.\n",
    "* On average in combination with all values of n-gram range, **binary set-of-words** settings on average did best, closely followed by bag-of-words counts, and with weighting by sentence length a bit further back.\n",
    "* On average in combination with all values of weights, **n-gram range of (1,4)** settings on average did best, followed by (1,5), then (1,3).\n",
    "* This result may not hold when using other preprocessing and may need to be re-done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Try joint pre-preprocessing and feature extraction optimization at once\n",
    "* Note these are done on single fold (first fold) due to the number of combinations (256 * 4 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ngram range to avoid 1 as bigram+ clearly helpful\n",
    "# will take a long time (256 * 4 * 3) settings, so will just do it on first fold\n",
    "ngram_feature_range = range(2,6)  \n",
    "\n",
    "results_feature_extraction_preprocess = []\n",
    "best_f_score = 0\n",
    "best_switches = []\n",
    "\n",
    "if False: # takes time, set to True to run\n",
    "    for w in count_weights[-1:]:\n",
    "        for n in ngram_feature_range:\n",
    "            #for k in feature_set_sizes:\n",
    "            #    print(w,n,k)\n",
    "            _N_ = n\n",
    "            _WEIGHT_ = w\n",
    "\n",
    "            for switches in combos:\n",
    "                preprocessing_switches = {k : False for k in preprocessing_switches.keys()}\n",
    "                for switch in switches:\n",
    "                    preprocessing_switches[switch] = True\n",
    "                print(\"*\" * 30)\n",
    "                print(preprocessing_switches)\n",
    "                # loading reviews\n",
    "                # initialize global lists that will be appended to by the methods below\n",
    "                raw_data = []          # the filtered data from the dataset file\n",
    "                train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "                test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "                # references to the data files\n",
    "                data_file_path = 'fake_news.tsv'\n",
    "\n",
    "                # Do the actual stuff (i.e. call the functions we've made)\n",
    "                # We parse the dataset and put it in a raw data list\n",
    "                print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "                      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "                load_data(data_file_path) \n",
    "\n",
    "                # We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "                # You do the cross validation on the 80% (training data)\n",
    "                # We print the number of training samples and the number of features before the split\n",
    "                print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "                      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "                global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "                split_and_preprocess_data(0.8)\n",
    "\n",
    "                # let's look at the representation of the first instance of training:\n",
    "                print(train_data[0])\n",
    "\n",
    "                # We print the number of training samples and the number of features after the split\n",
    "                print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "                      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "\n",
    "                all_scores = cross_validate(train_data, 10, first_fold_only=True)\n",
    "\n",
    "                f_score = all_scores[2]\n",
    "                print(w, n, preprocessing_switches, f_score)\n",
    "                results_feature_extraction_preprocess.append([w, n] + [(k,v) for k,v in preprocessing_switches.items()] + all_scores)\n",
    "                if f_score > best_f_score:\n",
    "                    best_f_score = f_score\n",
    "                    best_feature_extraction['w'] = w\n",
    "                    best_feature_extraction['n'] = n\n",
    "                    best_switches = switches\n",
    "   \n",
    "    best_preprocessing_switches = {k : False for k in preprocessing_switches.keys()}\n",
    "    for switch in best_switches:\n",
    "        best_preprocessing_switches[switch] = True\n",
    "    print(\"best f-score\", best_f_score, \"with best feature settings\", best_feature_extraction,\n",
    "              \"and best preprocessing settings\", best_preprocessing_switches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>n</th>\n",
       "      <th>convert_usernames</th>\n",
       "      <th>separate_out_punctuation</th>\n",
       "      <th>convert_number_words_to_digits</th>\n",
       "      <th>convert_numbers</th>\n",
       "      <th>remove_punctuation</th>\n",
       "      <th>convert_to_lowercase</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>apply_lemmatization</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>counts</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.623970</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.624761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622798</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.623668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622798</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.623668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622188</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.623408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622188</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.623408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.622028</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.623348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.622028</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.623348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>counts</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>counts</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>counts</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621432</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.622285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621439</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.622194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621439</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.622194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620556</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.621597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620556</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.621597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619961</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.621213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619961</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.621213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.620692</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.621069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.620692</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.621069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619738</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.620943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619738</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.620943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620065</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.620899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>binary</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620065</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.620899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619520</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.620667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619520</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.620667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>counts</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619053</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.620376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>counts</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619053</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.620376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618662</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.620025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618662</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.620025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569934</td>\n",
       "      <td>0.571951</td>\n",
       "      <td>0.570841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569934</td>\n",
       "      <td>0.571951</td>\n",
       "      <td>0.570841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569212</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.570785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569212</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.570785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568173</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.570013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568173</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.570013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.569325</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.569418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.569325</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.569418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.568166</td>\n",
       "      <td>0.570732</td>\n",
       "      <td>0.569285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.568166</td>\n",
       "      <td>0.570732</td>\n",
       "      <td>0.569285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.567807</td>\n",
       "      <td>0.570732</td>\n",
       "      <td>0.569056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.567807</td>\n",
       "      <td>0.570732</td>\n",
       "      <td>0.569056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.566757</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.567947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.566757</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.567947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>counts</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.565329</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.566980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>counts</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.565329</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.566980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.563251</td>\n",
       "      <td>0.565854</td>\n",
       "      <td>0.564391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.563251</td>\n",
       "      <td>0.565854</td>\n",
       "      <td>0.564391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.562946</td>\n",
       "      <td>0.564634</td>\n",
       "      <td>0.563723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.562946</td>\n",
       "      <td>0.564634</td>\n",
       "      <td>0.563723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561109</td>\n",
       "      <td>0.564634</td>\n",
       "      <td>0.562574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561109</td>\n",
       "      <td>0.564634</td>\n",
       "      <td>0.562574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.560385</td>\n",
       "      <td>0.564634</td>\n",
       "      <td>0.562073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.560385</td>\n",
       "      <td>0.564634</td>\n",
       "      <td>0.562073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561625</td>\n",
       "      <td>0.562195</td>\n",
       "      <td>0.561903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561625</td>\n",
       "      <td>0.562195</td>\n",
       "      <td>0.561903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.556256</td>\n",
       "      <td>0.558537</td>\n",
       "      <td>0.557279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555712</td>\n",
       "      <td>0.556098</td>\n",
       "      <td>0.555901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555712</td>\n",
       "      <td>0.556098</td>\n",
       "      <td>0.555901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>counts</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.554181</td>\n",
       "      <td>0.556098</td>\n",
       "      <td>0.555058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3072 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      weight  n  convert_usernames  separate_out_punctuation  \\\n",
       "0     counts  4              False                     False   \n",
       "1     binary  5              False                     False   \n",
       "2     binary  5               True                     False   \n",
       "3     binary  3              False                     False   \n",
       "4     binary  3               True                     False   \n",
       "5     binary  4              False                     False   \n",
       "6     binary  4               True                     False   \n",
       "7     binary  5              False                      True   \n",
       "8     binary  5               True                      True   \n",
       "9     counts  5              False                     False   \n",
       "10    counts  5               True                     False   \n",
       "11    counts  4               True                     False   \n",
       "12    binary  2              False                     False   \n",
       "13    binary  2               True                     False   \n",
       "14    binary  2              False                      True   \n",
       "15    binary  2               True                      True   \n",
       "16    binary  5              False                     False   \n",
       "17    binary  5               True                     False   \n",
       "18    binary  5              False                      True   \n",
       "19    binary  5               True                      True   \n",
       "20    binary  5              False                     False   \n",
       "21    binary  5               True                     False   \n",
       "22    binary  5              False                      True   \n",
       "23    binary  5               True                      True   \n",
       "24    binary  4              False                     False   \n",
       "25    binary  4               True                     False   \n",
       "26    counts  4              False                     False   \n",
       "27    counts  4               True                     False   \n",
       "28    binary  3              False                     False   \n",
       "29    binary  3               True                     False   \n",
       "...      ... ..                ...                       ...   \n",
       "3042  counts  2              False                     False   \n",
       "3043  counts  2               True                     False   \n",
       "3044  counts  2              False                     False   \n",
       "3045  counts  2               True                     False   \n",
       "3046  binary  3              False                     False   \n",
       "3047  binary  3               True                     False   \n",
       "3048  binary  2              False                     False   \n",
       "3049  binary  2               True                     False   \n",
       "3050  binary  2              False                     False   \n",
       "3051  binary  2               True                     False   \n",
       "3052  binary  2              False                      True   \n",
       "3053  binary  2               True                      True   \n",
       "3054  counts  2              False                      True   \n",
       "3055  counts  2               True                      True   \n",
       "3056  counts  3              False                     False   \n",
       "3057  counts  3               True                     False   \n",
       "3058  counts  2              False                     False   \n",
       "3059  counts  2               True                     False   \n",
       "3060  binary  2              False                     False   \n",
       "3061  binary  2               True                     False   \n",
       "3062  counts  2              False                     False   \n",
       "3063  counts  2               True                     False   \n",
       "3064  binary  2              False                     False   \n",
       "3065  binary  2               True                     False   \n",
       "3066  counts  2              False                     False   \n",
       "3067  counts  2               True                     False   \n",
       "3068  counts  2              False                      True   \n",
       "3069  counts  2              False                     False   \n",
       "3070  counts  2               True                     False   \n",
       "3071  counts  2               True                      True   \n",
       "\n",
       "      convert_number_words_to_digits  convert_numbers  remove_punctuation  \\\n",
       "0                              False            False                True   \n",
       "1                               True            False                True   \n",
       "2                               True            False                True   \n",
       "3                               True             True                True   \n",
       "4                               True             True                True   \n",
       "5                              False            False                True   \n",
       "6                              False            False                True   \n",
       "7                              False            False                True   \n",
       "8                              False            False                True   \n",
       "9                               True            False                True   \n",
       "10                              True            False                True   \n",
       "11                             False            False                True   \n",
       "12                             False            False                True   \n",
       "13                             False            False                True   \n",
       "14                             False            False                True   \n",
       "15                             False            False                True   \n",
       "16                             False            False                True   \n",
       "17                             False            False                True   \n",
       "18                              True            False                True   \n",
       "19                              True            False                True   \n",
       "20                              True             True                True   \n",
       "21                              True             True                True   \n",
       "22                              True            False                True   \n",
       "23                              True            False                True   \n",
       "24                              True            False                True   \n",
       "25                              True            False                True   \n",
       "26                              True            False                True   \n",
       "27                              True            False                True   \n",
       "28                             False            False                True   \n",
       "29                             False            False                True   \n",
       "...                              ...              ...                 ...   \n",
       "3042                            True            False               False   \n",
       "3043                            True            False               False   \n",
       "3044                            True             True                True   \n",
       "3045                            True             True                True   \n",
       "3046                           False            False               False   \n",
       "3047                           False            False               False   \n",
       "3048                            True             True               False   \n",
       "3049                            True             True               False   \n",
       "3050                           False            False               False   \n",
       "3051                           False            False               False   \n",
       "3052                            True             True                True   \n",
       "3053                            True             True                True   \n",
       "3054                           False             True               False   \n",
       "3055                           False             True               False   \n",
       "3056                           False            False               False   \n",
       "3057                           False            False               False   \n",
       "3058                            True            False               False   \n",
       "3059                            True            False               False   \n",
       "3060                           False            False               False   \n",
       "3061                           False            False               False   \n",
       "3062                           False            False               False   \n",
       "3063                           False            False               False   \n",
       "3064                            True            False               False   \n",
       "3065                            True            False               False   \n",
       "3066                            True             True               False   \n",
       "3067                            True             True               False   \n",
       "3068                            True             True                True   \n",
       "3069                           False            False               False   \n",
       "3070                           False            False               False   \n",
       "3071                            True             True                True   \n",
       "\n",
       "      convert_to_lowercase  remove_stopwords  apply_lemmatization         p  \\\n",
       "0                    False              True                 True  0.623970   \n",
       "1                     True             False                 True  0.622798   \n",
       "2                     True             False                 True  0.622798   \n",
       "3                     True             False                 True  0.622188   \n",
       "4                     True             False                 True  0.622188   \n",
       "5                    False             False                False  0.622028   \n",
       "6                    False             False                False  0.622028   \n",
       "7                    False             False                False  0.621106   \n",
       "8                    False             False                False  0.621106   \n",
       "9                     True             False                False  0.621106   \n",
       "10                    True             False                False  0.621106   \n",
       "11                   False              True                 True  0.621432   \n",
       "12                   False             False                 True  0.621439   \n",
       "13                   False             False                 True  0.621439   \n",
       "14                   False             False                 True  0.620556   \n",
       "15                   False             False                 True  0.620556   \n",
       "16                   False             False                False  0.619961   \n",
       "17                   False             False                False  0.619961   \n",
       "18                   False             False                False  0.620692   \n",
       "19                   False             False                False  0.620692   \n",
       "20                    True             False                False  0.619738   \n",
       "21                    True             False                False  0.619738   \n",
       "22                    True             False                 True  0.620065   \n",
       "23                    True             False                 True  0.620065   \n",
       "24                    True             False                 True  0.619520   \n",
       "25                    True             False                 True  0.619520   \n",
       "26                    True             False                False  0.619053   \n",
       "27                    True             False                False  0.619053   \n",
       "28                   False             False                False  0.618662   \n",
       "29                   False             False                False  0.618662   \n",
       "...                    ...               ...                  ...       ...   \n",
       "3042                  True              True                False  0.569934   \n",
       "3043                  True              True                False  0.569934   \n",
       "3044                  True              True                False  0.569212   \n",
       "3045                  True              True                False  0.569212   \n",
       "3046                  True              True                 True  0.568173   \n",
       "3047                  True              True                 True  0.568173   \n",
       "3048                  True              True                 True  0.569325   \n",
       "3049                  True              True                 True  0.569325   \n",
       "3050                  True             False                False  0.568166   \n",
       "3051                  True             False                False  0.568166   \n",
       "3052                 False              True                False  0.567807   \n",
       "3053                 False              True                False  0.567807   \n",
       "3054                  True              True                 True  0.566757   \n",
       "3055                  True              True                 True  0.566757   \n",
       "3056                  True              True                 True  0.565329   \n",
       "3057                  True              True                 True  0.565329   \n",
       "3058                  True              True                 True  0.563251   \n",
       "3059                  True              True                 True  0.563251   \n",
       "3060                  True              True                 True  0.562946   \n",
       "3061                  True              True                 True  0.562946   \n",
       "3062                  True             False                False  0.561109   \n",
       "3063                  True             False                False  0.561109   \n",
       "3064                  True              True                 True  0.560385   \n",
       "3065                  True              True                 True  0.560385   \n",
       "3066                  True             False                False  0.561625   \n",
       "3067                  True             False                False  0.561625   \n",
       "3068                 False              True                False  0.556256   \n",
       "3069                  True              True                 True  0.555712   \n",
       "3070                  True              True                 True  0.555712   \n",
       "3071                 False              True                False  0.554181   \n",
       "\n",
       "             r   f-score  \n",
       "0     0.630488  0.624761  \n",
       "1     0.629268  0.623668  \n",
       "2     0.629268  0.623668  \n",
       "3     0.625610  0.623408  \n",
       "4     0.625610  0.623408  \n",
       "5     0.626829  0.623348  \n",
       "6     0.626829  0.623348  \n",
       "7     0.626829  0.622313  \n",
       "8     0.626829  0.622313  \n",
       "9     0.626829  0.622313  \n",
       "10    0.626829  0.622313  \n",
       "11    0.628049  0.622285  \n",
       "12    0.623171  0.622194  \n",
       "13    0.623171  0.622194  \n",
       "14    0.623171  0.621597  \n",
       "15    0.623171  0.621597  \n",
       "16    0.625610  0.621213  \n",
       "17    0.625610  0.621213  \n",
       "18    0.628049  0.621069  \n",
       "19    0.628049  0.621069  \n",
       "20    0.625610  0.620943  \n",
       "21    0.625610  0.620943  \n",
       "22    0.626829  0.620899  \n",
       "23    0.626829  0.620899  \n",
       "24    0.625610  0.620667  \n",
       "25    0.625610  0.620667  \n",
       "26    0.624390  0.620376  \n",
       "27    0.624390  0.620376  \n",
       "28    0.623171  0.620025  \n",
       "29    0.623171  0.620025  \n",
       "...        ...       ...  \n",
       "3042  0.571951  0.570841  \n",
       "3043  0.571951  0.570841  \n",
       "3044  0.573171  0.570785  \n",
       "3045  0.573171  0.570785  \n",
       "3046  0.573171  0.570013  \n",
       "3047  0.573171  0.570013  \n",
       "3048  0.569512  0.569418  \n",
       "3049  0.569512  0.569418  \n",
       "3050  0.570732  0.569285  \n",
       "3051  0.570732  0.569285  \n",
       "3052  0.570732  0.569056  \n",
       "3053  0.570732  0.569056  \n",
       "3054  0.569512  0.567947  \n",
       "3055  0.569512  0.567947  \n",
       "3056  0.569512  0.566980  \n",
       "3057  0.569512  0.566980  \n",
       "3058  0.565854  0.564391  \n",
       "3059  0.565854  0.564391  \n",
       "3060  0.564634  0.563723  \n",
       "3061  0.564634  0.563723  \n",
       "3062  0.564634  0.562574  \n",
       "3063  0.564634  0.562574  \n",
       "3064  0.564634  0.562073  \n",
       "3065  0.564634  0.562073  \n",
       "3066  0.562195  0.561903  \n",
       "3067  0.562195  0.561903  \n",
       "3068  0.558537  0.557279  \n",
       "3069  0.556098  0.555901  \n",
       "3070  0.556098  0.555901  \n",
       "3071  0.556098  0.555058  \n",
       "\n",
       "[3072 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort results by best f-score\n",
    "if False:  # set to False if above search is not run\n",
    "    # sort the results by best f-score:\n",
    "    results_feature_extraction_preprocess = sorted(results_feature_extraction_preprocess,\n",
    "                                                   key=lambda x:x[-1], reverse=True)\n",
    "    df = pd.DataFrame([[x for x in row[:2]] + [x[1] for x in row[2:-3]] + row[-3:] for row in results_feature_extraction_preprocess],\n",
    "                  columns=[\"weight\", \"n\"] + [x[0] for x in results_feature_extraction_preprocess[0][2:-3]] +  [\"p\", \"r\", \"f-score\"])\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary 0.5998666354471951\n",
      "counts 0.5967058465038103\n",
      "weighted 0.5977354419194072\n"
     ]
    }
   ],
   "source": [
    "# which feature counting/weights technique is most useful (in combination with other params)?\n",
    "if False:  # set to False if above search is not run\n",
    "    for w in count_weights:\n",
    "        print(w, sum(df[df[\"weight\"]==w]['f-score']) / len(df[df[\"weight\"]==w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.5931914577999501\n",
      "3 0.5990706244681215\n",
      "4 0.6002498616327715\n",
      "5 0.5998986212597056\n"
     ]
    }
   ],
   "source": [
    "# which ngram n value is most useful (in combination with other params)?\n",
    "if False:  # set to False if above search is not run\n",
    "    for n in range(2,6):\n",
    "        print(n, sum(df[df[\"n\"]==n]['f-score']) / len(df[df[\"n\"]==n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_usernames 0.5980895269054742\n",
      "separate_out_punctuation 0.5981813991781045\n",
      "convert_number_words_to_digits 0.5970608680605519\n",
      "convert_numbers 0.5970483434596471\n",
      "remove_punctuation 0.6017270909473051\n",
      "convert_to_lowercase 0.5979548945941139\n",
      "remove_stopwords 0.5949706694511793\n",
      "apply_lemmatization 0.5976712061553849\n"
     ]
    }
   ],
   "source": [
    "# which feature being true tends to help more?\n",
    "if False:  # set as False if above search not run\n",
    "    for key in preprocessing_switches.keys():\n",
    "        print(key, sum(df[df[key]==True]['f-score']) / len(df[df[key]==True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on joint feature extraction and preprocessing optimizatino (for report)\n",
    "* The result from the independent optimization on the full x-val is the same in that the best feature extraction settings were **n-gram range of (1,4)** and using **bag-of-words counts**\n",
    "* However for feature preprocessing, the best techqniues were found to be **remove_punctuation**, **remove_stopwords** and **apply_lemmatization**, somewhat more preprocessing and normalization thatn before.\n",
    "* On average in combination with all values of weights and preprocessing, the result is unchanged that **n-gram range of (1,4)** settings on average did best, followed by (1,5), then (1,3).\n",
    "* On average in combination with all values of n-gram range, again, **binary set-of-words** settings on average did best, closely followed by bag-of-words counts, and with weighting by sentence length a bit further back.\n",
    "* This result may not hold when using other preprocessing and may need to be re-done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best settings from joint optimization:\n",
    "_WEIGHT_ = 'counts'\n",
    "_N_ =  4\n",
    "preprocessing_switches = {'convert_usernames': False,\n",
    "  'separate_out_punctuation': False,\n",
    "  'convert_number_words_to_digits': False,\n",
    "  'convert_numbers': False,\n",
    "  'remove_punctuation': True,\n",
    "  'convert_to_lowercase': False,\n",
    "  'remove_stopwords': True,\n",
    "  'apply_lemmatization': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10241 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "(Counter({'1@Says': 1, '1@Annies': 1, '1@List': 1, '1@political': 1, '1@group': 1, '1@support': 1, '1@thirdtrimester': 1, '1@abortion': 1, '1@demand': 1, '1@</s>': 1, '2@<s> Says': 1, '2@Says Annies': 1, '2@Annies List': 1, '2@List political': 1, '2@political group': 1, '2@group support': 1, '2@support thirdtrimester': 1, '2@thirdtrimester abortion': 1, '2@abortion demand': 1, '2@demand </s>': 1, '3@<s> <s> Says': 1, '3@<s> Says Annies': 1, '3@Says Annies List': 1, '3@Annies List political': 1, '3@List political group': 1, '3@political group support': 1, '3@group support thirdtrimester': 1, '3@support thirdtrimester abortion': 1, '3@thirdtrimester abortion demand': 1, '3@abortion demand </s>': 1, '4@<s> <s> <s> Says': 1, '4@<s> <s> Says Annies': 1, '4@<s> Says Annies List': 1, '4@Says Annies List political': 1, '4@Annies List political group': 1, '4@List political group support': 1, '4@political group support thirdtrimester': 1, '4@group support thirdtrimester abortion': 1, '4@support thirdtrimester abortion demand': 1, '4@thirdtrimester abortion demand </s>': 1}), 'FAKE')\n",
      "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
      "Training Samples: \n",
      "8192\n",
      "Features: \n",
      "314940\n",
      "Fold start on items 0 - 820\n",
      "Training Classifier...\n",
      "Fold start on items 820 - 1640\n",
      "Training Classifier...\n",
      "Fold start on items 1640 - 2460\n",
      "Training Classifier...\n",
      "Fold start on items 2460 - 3280\n",
      "Training Classifier...\n",
      "Fold start on items 3280 - 4100\n",
      "Training Classifier...\n",
      "Fold start on items 4100 - 4920\n",
      "Training Classifier...\n",
      "Fold start on items 4920 - 5740\n",
      "Training Classifier...\n",
      "Fold start on items 5740 - 6560\n",
      "Training Classifier...\n",
      "Fold start on items 6560 - 7380\n",
      "Training Classifier...\n",
      "Fold start on items 7380 - 8200\n",
      "Training Classifier...\n",
      "0.6047976516109348\n"
     ]
    }
   ],
   "source": [
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# let's look at the representation of the first instance of training:\n",
    "print(train_data[0])\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "\n",
    "all_scores = cross_validate(train_data, 10, first_fold_only=False)\n",
    "f_score = all_scores[2]\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there is a slight improvement on the full cross-val experiment f-score to **0.605**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 Hyperparameter optimization of the linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
       "                          'max_iter': [1, 5, 10, 50, 100, 500, 1000, 5000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final hyperparameter tuning of the linearSVC on cross-val across the training data\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "parameters = [{\n",
    "#'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'], \n",
    "'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "'max_iter': [1,5,10, 50, 100, 500, 1000, 5000]}]\n",
    "\n",
    "clf = GridSearchCV(\n",
    "        LinearSVC(), parameters, scoring='accuracy'\n",
    "    )\n",
    "\n",
    "clf.fit(DictVectorizer().fit_transform([x[0] for x in train_data]), [x[1] for x in train_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 10}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "_C_ = clf.best_params_[\"C\"]\n",
    "_MAX_ITER_ = clf.best_params_[\"max_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([\n",
    "     ('svc', LinearSVC(C=_C_, max_iter=_MAX_ITER_))])\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'convert_usernames': False, 'separate_out_punctuation': False, 'convert_number_words_to_digits': False, 'convert_numbers': False, 'remove_punctuation': True, 'convert_to_lowercase': False, 'remove_stopwords': True, 'apply_lemmatization': True}\n",
      "weights counts\n",
      "n 4\n",
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10241 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "(Counter({'1@Says': 1, '1@Annies': 1, '1@List': 1, '1@political': 1, '1@group': 1, '1@support': 1, '1@thirdtrimester': 1, '1@abortion': 1, '1@demand': 1, '1@</s>': 1, '2@<s> Says': 1, '2@Says Annies': 1, '2@Annies List': 1, '2@List political': 1, '2@political group': 1, '2@group support': 1, '2@support thirdtrimester': 1, '2@thirdtrimester abortion': 1, '2@abortion demand': 1, '2@demand </s>': 1, '3@<s> <s> Says': 1, '3@<s> Says Annies': 1, '3@Says Annies List': 1, '3@Annies List political': 1, '3@List political group': 1, '3@political group support': 1, '3@group support thirdtrimester': 1, '3@support thirdtrimester abortion': 1, '3@thirdtrimester abortion demand': 1, '3@abortion demand </s>': 1, '4@<s> <s> <s> Says': 1, '4@<s> <s> Says Annies': 1, '4@<s> Says Annies List': 1, '4@Says Annies List political': 1, '4@Annies List political group': 1, '4@List political group support': 1, '4@political group support thirdtrimester': 1, '4@group support thirdtrimester abortion': 1, '4@support thirdtrimester abortion demand': 1, '4@thirdtrimester abortion demand </s>': 1}), 'FAKE')\n",
      "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
      "Training Samples: \n",
      "8192\n",
      "Features: \n",
      "314940\n",
      "Fold start on items 0 - 820\n",
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold start on items 820 - 1640\n",
      "Training Classifier...\n",
      "Fold start on items 1640 - 2460\n",
      "Training Classifier...\n",
      "Fold start on items 2460 - 3280\n",
      "Training Classifier...\n",
      "Fold start on items 3280 - 4100\n",
      "Training Classifier...\n",
      "Fold start on items 4100 - 4920\n",
      "Training Classifier...\n",
      "Fold start on items 4920 - 5740\n",
      "Training Classifier...\n",
      "Fold start on items 5740 - 6560\n",
      "Training Classifier...\n",
      "Fold start on items 6560 - 7380\n",
      "Training Classifier...\n",
      "Fold start on items 7380 - 8200\n",
      "Training Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.61408808399468, 0.6195500420521447, 0.6073098127444935]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION 3 - Make sure there is a function call here to the\n",
    "# crossValidate function on the training set to get your results\n",
    "print(preprocessing_switches)\n",
    "print(\"weights\", _WEIGHT_)\n",
    "print(\"n\", _N_)\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# let's look at the representation of the first instance of training:\n",
    "print(train_data[0])\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "cross_validate(train_data, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there is another slight improvement on the full cross-val experiment f-score to **0.607**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Counter({'1@The': 1, '1@Bush': 1, '1@tax': 1, '1@cut': 1, '1@helped': 1, '1@create': 1, '1@substantial': 1, '1@part': 1, '1@deficit': 1, '1@</s>': 1, '2@<s> The': 1, '2@The Bush': 1, '2@Bush tax': 1, '2@tax cut': 1, '2@cut helped': 1, '2@helped create': 1, '2@create substantial': 1, '2@substantial part': 1, '2@part deficit': 1, '2@deficit </s>': 1, '3@<s> <s> The': 1, '3@<s> The Bush': 1, '3@The Bush tax': 1, '3@Bush tax cut': 1, '3@tax cut helped': 1, '3@cut helped create': 1, '3@helped create substantial': 1, '3@create substantial part': 1, '3@substantial part deficit': 1, '3@part deficit </s>': 1, '4@<s> <s> <s> The': 1, '4@<s> <s> The Bush': 1, '4@<s> The Bush tax': 1, '4@The Bush tax cut': 1, '4@Bush tax cut helped': 1, '4@tax cut helped create': 1, '4@cut helped create substantial': 1, '4@helped create substantial part': 1, '4@create substantial part deficit': 1, '4@substantial part deficit </s>': 1}), 'REAL')\n",
      "Training Classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.59      0.43      0.50       926\n",
      "        REAL       0.62      0.75      0.68      1123\n",
      "\n",
      "    accuracy                           0.61      2049\n",
      "   macro avg       0.60      0.59      0.59      2049\n",
      "weighted avg       0.60      0.61      0.60      2049\n",
      "\n",
      "Done training!\n",
      "Precision: 0.603437\n",
      "Recall: 0.606637\n",
      "F Score:0.595358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the tranin data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
    "    report = classification_report(test_true, test_pred, output_dict=True)\n",
    "    print(classification_report(test_true, test_pred))\n",
    "    print(\"Done training!\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
